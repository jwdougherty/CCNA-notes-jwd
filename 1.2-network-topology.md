# [Cisco Networking Academy's Introduction to Scaling Networks](https://www.ciscopress.com/articles/article.asp?p=2189637&seqNum=3)


## Introduction (1.0.1.1)
As a business grows, so do its networking requirements. Businesses rely on the network infrastructure to provide mission-critical services. Network outages can result in lost revenue and lost customers. Network designers must design and build an enterprise network that is scalable and highly available.

This chapter introduces strategies that can be used to systematically design a highly functional network, such as the hierarchical network design model, the Cisco Enterprise Architecture, and appropriate device selections. The goals of network design are to:
- limit the number of devices impacted by the failure of a single network device,
- provide a plan and path for growth,
- and create a reliable network.

>   Class Activity 1.0.1.2: Network by Design
>
> 
>    Your employer is opening a new branch office.
> 
>    You have been reassigned to the site as the network administrator, where your job will be to design and maintain the new branch network.
> 
>    The network administrators at the other branches used the Cisco three-layer hierarchical model when designing their networks. You decide to use the same approach.
> 
>    To get an idea of what using the hierarchical model can do to enhance the design process, you research the topic.

## Implementing a Network Design (1.1)

Effective network design implementation requires a solid understanding of the current state of recommended network models and their ability to scale as the network grows.
        
### Hierarchical Network Design (1.1.1)

The hierarchical network model and the Cisco Enterprise Architecture are models to consider when designing a network. This section reviews the importance of scalability and how these models can effectively address that need.

### The Need to Scale the Network (1.1.1.1)

Businesses increasingly rely on their network infrastructure to provide mission-critical services. As businesses grow and evolve, they hire more employees, open branch offices, and expand into global markets. These changes directly affect the requirements of a network. A large business environment with many users, locations, and systems is referred to as an enterprise. The network that is used to support the business enterprise is called an enterprise network.

In Figure 1-1, the following steps occur as the network grows from a small company to a global enterprise:

 1. The company begins as a small, single-location company.
 2. The company increases its number of employees.
 3. The company grows to multiple locations in the same city.
 4. The enterprise grows to multiple cities.
 5. The enterprise hires teleworkers.
 6. The enterprise expands to other countries (not all enterprises are international).
 7. The enterprise centralizes network management in a Network Operations Center (NOC).
   
![Figure1-1](https://www.ciscopress.com/content/images/chap1_9781587133282/elementLinks/01fig01.jpg)

    Figure 1-1 Scaling the Network as the Business Grows

An enterprise network must support the exchange of various types of network traffic, including data files, email, IP telephony, and video applications for multiple business units. All enterprise networks must

    Support critical applications
    Support converged network traffic
    Support diverse business needs
    Provide centralized administrative control

Enterprise Business Devices (1.1.1.2)

Users expect enterprise networks, such as the example shown in Figure 1-2, to be up 99.999 percent of the time. Outages in the enterprise network prevent the business from performing normal activities, which can result in a loss of revenue, customers, data, and opportunities.
Figure 1-2

Figure 1-2 Large Enterprise Network Design

To obtain this level of reliability, high-end, enterprise-class equipment is commonly installed in the enterprise network. Designed and manufactured to more stringent standards than lower-end devices, enterprise equipment moves large volumes of network traffic.

Enterprise-class equipment is designed for reliability, with features such as redundant power supplies and failover capabilities. Failover capability refers to the ability of a device to switch from a nonfunctioning module, service, or device to a functioning one with little or no break in service.

Purchasing and installing enterprise-class equipment does not eliminate the need for proper network design.
Hierarchical Network Design (1.1.1.3)

To optimize bandwidth on an enterprise network, the network must be organized so that traffic stays local and is not propagated unnecessarily onto other portions of the network. Using the three-layer hierarchical design model helps organize the network.

This model divides the network functionality into three distinct layers, as shown in Figure 1-3:

    Access layer
    Distribution layer

    Core layer
    Figure 1-3

    Figure 1-3 Hierarchical Design Model

Each layer is designed to meet specific functions.

The access layer provides connectivity for the users. The distribution layer is used to forward traffic from one local network to another. Finally, the core layer represents a high-speed backbone layer between dispersed networks. User traffic is initiated at the access layer and passes through the other layers if the functionality of those layers is required.

Even though the hierarchical model has three layers, some smaller enterprise networks might implement a two-tier hierarchical design. In a two-tier hierarchical design, the core and distribution layers are collapsed into one layer, reducing cost and complexity, as shown in Figure 1-4.
Figure 1-4

Figure 1-4 Collapsed Core
Cisco Enterprise Architecture (1.1.1.4)

The Cisco Enterprise Architecture divides the network into functional components while still maintaining the core, distribution, and access layers. As Figure 1-5 shows, the primary Cisco Enterprise Architecture modules include

    Enterprise Campus
    Enterprise Edge
    Service Provider Edge

    Remote
    Figure 1-5

    Figure 1-5 Enterprise Architecture

Enterprise Campus

The Enterprise Campus consists of the entire campus infrastructure, to include the access, distribution, and core layers. The access layer module contains Layer 2 or Layer 3 switches to provide the required port density. Implementation of VLANs and trunk links to the building distribution layer occurs here. Redundancy to the building distribution switches is important. The distribution layer module aggregates building access using Layer 3 devices. Routing, access control, and QoS are performed at this distribution layer module. The core layer module provides high-speed interconnectivity between the distribution layer modules, data center server farms, and the enterprise edge. Redundancy, fast convergence, and fault tolerance are the focus of the design in this module.

In addition to these modules, the Enterprise Campus can include other submodules such as

    Server Farm and Data Center Module: This area provides high-speed connectivity and protection for servers. It is critical to provide security, redundancy, and fault tolerance. The network management systems monitor performance by monitoring device and network availability.
    Services Module: This area provides access to all services, such as IP Telephony services, wireless controller services, and unified services.

Enterprise Edge

The Enterprise Edge consists of the Internet, VPN, and WAN modules connecting the enterprise with the service provider’s network. This module extends the enterprise services to remote sites and enables the enterprise to use Internet and partner resources. It provides QoS, policy reinforcement, service levels, and security.
Service Provider Edge

The Service Provider Edge provides Internet, Public Switched Telephone Network (PSTN), and WAN services.

All data that enters or exits the Enterprise Composite Network Model (ECNM) passes through an edge device. This is the point where all packets can be examined and a decision made whether the packet should be allowed on the enterprise network. Intrusion detection systems (IDS) and intrusion prevention systems (IPS) can also be configured at the enterprise edge to protect against malicious activity.
Failure Domains (1.1.1.5)

A well-designed network not only controls traffic but also limits the size of failure domains. A failure domain is the area of a network that is impacted when a critical device or network service experiences problems.

The function of the device that initially fails determines the impact of a failure domain. For example, a malfunctioning switch on a network segment normally affects only the hosts on that segment. However, if the router that connects this segment to others fails, the impact is much greater.

The use of redundant links and reliable enterprise-class equipment minimizes the chance of disruption in a network. Smaller failure domains reduce the impact of a failure on company productivity. They also simplify the troubleshooting process, thereby shortening the downtime for all users.

Failure domains often include other, smaller failure domains. For example, Figure 1-6 shows the following failure domains:

    If the Edge Router fails, it will impact every device connected to it.
    If S1 fails, it will impact H1, H2, H3, and AP1.
    If S2 fails, it will impact S3, H4, H5, and H6.
    If AP1 fails, it will impact H1.

    If S3 fails, it will impact H5 and H6.
    Figure 1-6

    Figure 1-6 Failure Domain Examples

Limiting the Size of Failure Domains

Because a failure at the core layer of a network can have a potentially large impact, the network designer often concentrates on efforts to prevent failures. These efforts can greatly increase the cost of implementing the network. In the hierarchical design model, it is easiest and usually least expensive to control the size of a failure domain in the distribution layer. In the distribution layer, network errors can be contained to a smaller area, thus affecting fewer users. When using Layer 3 devices at the distribution layer, every router functions as a gateway for a limited number of access layer users.
Switch Block Deployment

Routers, or multilayer switches, are usually deployed in pairs, with access layer switches evenly divided between them. This configuration is referred to as a building, or departmental, switch block. Each switch block acts independently of the others. As a result, the failure of a single device does not cause the network to go down. Even the failure of an entire switch block does not affect a significant number of end users.

Activity 1.1.1.6: Identify Cisco Enterprise Architecture Modules
interactive_graphic.jpg

Go to the course online to perform this practice activity.
Expanding the Network (1.1.2)

A solid network design is not all that is needed for network expansion. This section reviews the features necessary to ensure that the network scales well as the company grows.
Design for Scalability (1.1.2.1)

To support an enterprise network, the network designer must develop a strategy to enable the network to be available and to scale effectively and easily. Included in a basic network design strategy are the following recommendations:

    Use expandable, modular equipment or clustered devices that can be easily upgraded to increase capabilities. Device modules can be added to the existing equipment to support new features and devices without requiring major equipment upgrades. Some devices can be integrated in a cluster to act as one device to simplify management and configuration.
    Design a hierarchical network to include modules that can be added, upgraded, and modified, as necessary, without affecting the design of the other functional areas of the network. For example, you can create a separate access layer that can be expanded without affecting the distribution and core layers of the campus network.
    Create an IPv4 or IPv6 address strategy that is hierarchical. Careful address planning eliminates the need to re-address the network to support additional users and services.
    Choose routers or multilayer switches to limit broadcasts and filter other undesirable traffic from the network. Use Layer 3 devices to filter and reduce traffic to the network core.

Figure 1-7 shows examples of some more advanced network requirements.
Figure 1-7

Figure 1-7 Design for Scalability

Advanced network design requirements shown in Figure 1-7 include

    Implementing redundant links in the network between critical devices and between access layer and core layer devices.
    Implementing multiple links between equipment, with either link aggregation (EtherChannel) or equal-cost load balancing, to increase bandwidth. Combining multiple Ethernet links into a single, load-balanced EtherChannel configuration increases available bandwidth. EtherChannel implementations can be used when budget restrictions prohibit purchasing high-speed interfaces and fiber runs.
    Implementing wireless connectivity to allow for mobility and expansion.
    Using a scalable routing protocol and implementing features within that routing protocol to isolate routing updates and minimize the size of the routing table.

Planning for Redundancy (1.1.2.2)

Redundancy is a critical design feature for most company networks.
Implementing Redundancy

For many organizations, the availability of the network is essential to supporting business needs. Redundancy is an important part of network design for preventing disruption of network services by minimizing the possibility of a single point of failure. One method of implementing redundancy is by installing duplicate equipment and providing failover services for critical devices.

Another method of implementing redundancy is using redundant paths, as shown in Figure 1-8.
Figure 1-8

Figure 1-8 LAN Redundancy

Redundant paths offer alternate physical paths for data to traverse the network. Redundant paths in a switched network support high availability. However, because of the operation of switches, redundant paths in a switched Ethernet network can cause logical Layer 2 loops. For this reason, Spanning Tree Protocol (STP) is required.

STP allows for the redundancy required for reliability but eliminates the switching loops. It does this by providing a mechanism for disabling redundant paths in a switched network until the path is necessary, such as when failures occur. STP is an open standard protocol, used in a switched environment to create a loop-free logical topology.

More details about LAN redundancy and the operation of STP are covered in Chapter 2, “LAN Redundancy.”
Increasing Bandwidth (1.1.2.3)

Bandwidth demand continues to grow as users increasingly access video content and migrate to IP phones. EtherChannel can quickly add more bandwidth.
Implementing EtherChannel

In hierarchical network design, some links between access and distribution switches might need to process a greater amount of traffic than other links. As traffic from multiple links converges onto a single, outgoing link, it is possible for that link to become a bottleneck. Link aggregation allows an administrator to increase the amount of bandwidth between devices by creating one logical link made up of several physical links. EtherChannel is a form of link aggregation used in switched networks, as shown in Figure 1-9.
Figure 1-9

Figure 1-9 Advantages of EtherChannel

EtherChannel uses the existing switch ports; therefore, additional costs to upgrade the link to a faster and more expensive connection are not necessary. The Ether-Channel is seen as one logical link using an EtherChannel interface. Most configuration tasks are done on the EtherChannel interface, instead of on each individual port, ensuring configuration consistency throughout the links. Finally, the EtherChannel configuration takes advantage of load balancing between links that are part of the same EtherChannel, and depending on the hardware platform, one or more load-balancing methods can be implemented.

EtherChannel operation and configuration will be covered in more detail in Chapter 3, “LAN Aggregation.”
Expanding the Access Layer (1.1.2.4)

Except in the most secure setting, today’s users expect wireless access to the networks.
Implementing Wireless Connectivity

The network must be designed to be able to expand network access to individuals and devices, as needed. An increasingly important aspect of extending access layer connectivity is through wireless connectivity. Providing wireless connectivity offers many advantages, such as increased flexibility, reduced costs, and the ability to grow and adapt to changing network and business requirements.

To communicate wirelessly, end devices require a wireless NIC that incorporates a radio transmitter/receiver and the required software driver to make it operational. Additionally, a wireless router or a wireless access point (AP) is required for users to connect, as shown in Figure 1-10.
Figure 1-10

Figure 1-10 Wireless LANs

There are many considerations when implementing a wireless network, such as the types of wireless devices to use, wireless coverage requirements, interference considerations, and security considerations.

Wireless operation and implementation will be covered in more detail in Chapter 4, “Wireless LANs.”
Fine-tuning Routing Protocols (1.1.2.5)

Routing protocol configuration is usually rather straightforward. However, to take full advantage of a protocol’s feature set, it is often necessary to modify the configuration.
Managing the Routed Network

Enterprise networks and ISPs often use more advanced protocols, such as link-state protocols, because of their hierarchical design and ability to scale for large networks.

Link-state routing protocols such as Open Shortest Path First (OSPF), as shown in Figure 1-11, work well for larger hierarchical networks, where fast convergence is important.
Figure 1-11

Figure 1-11 Single-Area OSPF

OSPF routers establish and maintain neighbor adjacency or adjacencies with other connected OSPF routers. When routers initiate an adjacency with neighbors, an exchange of link-state updates begins. Routers reach a FULL state of adjacency when they have synchronized views on their link-state database. With OSPF, link-state updates are sent when network changes occur.

OSPF is a popular link-state routing protocol that can be fine-tuned in many ways. Chapter 5, “Adjust and Troubleshoot Single-Area OSPF,” will cover some of the more advanced features of OSPF configuration and troubleshooting.

Additionally, OSPF supports a two-layer hierarchical design, or multiarea OSPF, as shown in Figure 1-12.
Figure 1-12

Figure 1-12 Multiarea OSPF

All OSPF networks begin with Area 0, also called the backbone area. As the network is expanded, other nonbackbone areas can be created. All nonbackbone areas must directly connect to area 0. Chapter 6, “Multiarea OSPF,” introduces the benefits, operation, and configuration of multiarea OSPF.

Another popular routing protocol for larger networks is Enhanced Interior Gateway Routing Protocol (EIGRP). Cisco developed EIGRP as a proprietary distance vector routing protocol with enhanced capabilities. Although configuring EIGRP is relatively simple, the underlying features and options of EIGRP are extensive and robust. For example, EIGRP uses multiple tables to manage the routing process using Protocol Dependent Modules (PDM), as shown in Figure 1-13.
Figure 1-13

Figure 1-13 EIGRP Protocol Dependent Modules (PDM)

EIGRP contains many features that are not found in any other routing protocols. It is an excellent choice for large, multiprotocol networks that employ primarily Cisco devices.

Chapter 7, “EIGRP,” introduces the operation and configuration of the EIGRP routing protocol, while Chapter 8, “EIGRP Advanced Configurations and Troubleshooting,” covers some of the more advanced configuration options of EIGRP.
